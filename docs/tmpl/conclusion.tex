\section{Discussion and Future work}
The silicon industry has chosen multicore as new
direction. However, diverging multicore architectures enlarge the gap between algorithm-centric programmer and
computer system developers.  Conventional C/C++ programming language
can not reflect hardware essence any more.  Existing ad-hoc techniques
or platform-dependent programming language pose issues of generality
and portability. Source-to-source transformation can meet the challenge
and help tailor programs to specific multicore architectures.

%Not only the more processor cores but also
%elaborated memory hierarchy and exposed communication are adopted by
%new multicore architectures. More worse, 

We present a template metaprogramming approach to perform source-to-source
transformation for programs with rich information. Because it applies 
metaprogramming technique, template library is flexible enough to
apply any parallel
patterns and execution models. In addition, our approach
is extensible. Instead of modifying a compiler to add
annotations or language constructs, we implement the whole
functionalities by template mechanism. Template metaprogramming is
intimate for C++ programmers so they can extend the library to
facilitate proper parallel patterns and new architectural
features.  Our approach follows ISO C++ standards, which mean the
methodology is guaranteed to work across platforms.  Experiments shows
that our template approach can transform algorithms into SPMD threads
with competitive performance. These transformation are available for
both CPU and GPU, the cost of migration is manageable. We also
transform a group of standalone function wrappers into a
stream using our template library. It demonstrates that template
metaprogramming is powerful enough to support more than one parallel pattern.

%Our programming model bridges algorithm experts and diverging multcore
%architectures. Domain-specific experts focus on algorithms in form of
%conventional programming languages. They wrap functions to template
%classes and then pass them to \emph{TF class} as template parameter. Template
%mechniasm takes responisbility to transform source code according to
%their targets.

Streaming is an important computation model for innovative
multicore architectures. We partially exploit GPU functionality in this
paper though, transformation for GPU is quite
straightforward.  It is still unclear how many efforts need to
pay for a full-blown template library, which support
streaming computation. Libvina can only deal with regular
data. Future work on view class  will concentrate on supporting general operations like gather and scatter etc.  
Currently, kernel functions in GPU prohibit recursion. So we believe that
it is beneficial to introduce template recursion for GPU kernel functions. TF classes which support strip-mined memory access and loop iteration transformation are
particularly attractive for GPU targets because because  GPUs
provide memory coalescence for specific access patterns.

On CPU, source-to-source transformation should go on improving data
locality of programs. We plan to explore template approach to  generalize
blocking and tiling techniques.  It is also possible to re-structure
or prefetch data using template metaprograming accompanying with
runtime library.

General applications also contain a variety of static information to
optimize.The problem is that their memory footprints are irregular and
very hard to identify. It is desirable to explores new TF classes to facilitate
transforming source code close to target architectures using the static
information.
