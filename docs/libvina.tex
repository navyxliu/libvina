
%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[10pt, conference, compsocconf]{IEEEtran}
% Add the compsocconf option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
   \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
   \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
   \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
   \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
   \graphicspath{{./}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
   \DeclareGraphicsExtensions{.png, .pdf, .eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.





% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{A Template Approach to transform Sources for Multicore Architectures}


% author names and affiliations
% use a multiple column layout for up to two different
% affiliations

%\author{\IEEEauthorblockN{Authors Name/s per 1st Affiliation (Author)}
%\IEEEauthorblockA{line 1 (of Affiliation): dept. name of organization\\
%line 2: name of organization, acronyms acceptable\\
%line 3: City, Country\\
%line 4: Email: name@xyz.com}
%\and
%\IEEEauthorblockN{Authors Name/s per 2nd Affiliation (Author)}
%\IEEEauthorblockA{line 1 (of Affiliation): dept. name of organization\\
%line 2: name of organization, acronyms acceptable\\
%line 3: City, Country\\
%line 4: Email: name@xyz.com}
%}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
\author{\IEEEauthorblockN{Xin Liu}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle


\begin{abstract}
In advent of multicore era, plain C/C++ programming language can not fully reflects the hardware artchitecture any more. A source-to-source compilation assists in adapting programs close to contemporary multicore hardwares. We proposed a template-based approach to perform the transformation for programs with rich static information. We presented template metaprogramming to conduct parallelization and memory hierarchical optimization. It enables programmers to adapte new architectural feature or parallel computation models by extending template library. 
In this paper, we implemented a prototype template library -- libvina to demonstrate the idea. Finally, We evaluate the performance on commodity x86 and GPU platforms by a variaty of typical applications in multimedia and scientific fields. The experiments show that our approach is flexible to support multiple computational models. In addition, the experimental results reveal that our approach incurs little runtime overhead because it takes effects in compile-time.
\end{abstract}

\begin{IEEEkeywords}
static analysis; Compiler optimization; parallelization
\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\section{Introduction}
In multicore period, hardware architects rely on parallelism and memory hierarchy to enhance performance. Both cloned processors and elaborated storage-on-chip require programmer to restructure their source code and keep tuning binaries for a specific target. Therefore, writing a high-performance application requires non-trivial knowledge of underlying machine's architecture. The gap between hardware vendors and software developers extends development cycle, which increases marketing cost and risks for innovative multicore architectures in silicon industry.

Algorithm experts usually focus on their specific domains and have limited insights on diverging computer systems. They expect hardware and optimized compiler to guarantee decent performance for their programs. The expectation was roughly held until parallel system was introduced to computer community. Since frequency of general purpose processor stops growing faster, it has been hard to obtain free performance enhancement from hardware's refinement any more. Essentially, plain C/C++ can not fully reflect contemplate architecture such as multicore and distributed storage-on-chip. Researchers have admitted that it is tremendously challenging for optimizing sequential code by a compiler, so the answer to bridge programmer to parallel hardware relies on language and library to express concurrency richer than ever.

Designing new parallel programming is possible. Many functional languages \cite{b13} with inherent concurrency supports have emerged to the horizon of computer. However, a conservative programmer may turn them down because there are still lack of convincing evidences to demonstrate programmability and efficiency comparing to traditional programming languages. Another reason is software cost. Considering the time span which a large computer system serves, hardwares are cheap and become cheaper with time passing; software and well-trained personnel are expensive. Even numerous legacy systems designed with little consideration of multi-threaded environment at that time, vendors usually prefer to maintain and update legacy software systems for current and future hardwares rather than rebuilding them from scratch. 

One side, software developers insist on classic programming diagrams and are reluctant to rewrite existing sources. On the other side, exploiting horsepower of modern processors for existing and new systems is a moderate issue. Therefore, it is desirable to extend traditional programming languages to balance the trade-off.

Many programming languages extending popular programming languages had been proposed for multicore. However, most of existing solutions aimed at specific architectures or computation models. UPC and OpenMP are designed for shared memory system \cite{b15}. CUDA works on vender-dependent GPU architecture for streaming computation; Sequoia \cite{b1} is an attempt to customize code-generation rules by XML configuration, however, it follows the similar restriction by enforce programs execute on a tree of abstract machines.

Our approach performs source-to-source transformation by compiler like Sequoia and OpenMP. We shared the same idea of  ~\cite{b1} to generate a cluster of subprocedures for a task recursively. Instead of modifying compiler and introducing new language constructs, we exploit the capability of C++ template mechanism to achieve translation. All transformation rules are programmed in C++ meta-programming \cite{b10} and are conducted by a group of template class when that are instantiated. The primary limitation is that only type and static constant value are available in compile time. Therefore, it only works for programs which own rich static information. Fortunately, applications with this characteristic are pervasive in multimedia, digital processing, and scientific computations 

Because libvina takes effect in compile time, it is possible to avoid from deploying runtime system, which means that it can incur minimal runtime cost. Besides that, our template-based approach imposes few restricts comparing with other static approaches:

\begin{itemize}
\item Thread-independent: It is possible to generate all kind of threads for target, including pthread, native LWP provided by OS, even vendor-dependent thread. 

\item Execution-independent: Our approach does not bind to any execution model. Utilizing template transform, we can change program into SPMD threads to exploit parallelism from multicore; chain many subroutines to build a pipeline to hide latency of memory; and separate program into blocks to improve locality. 

\item Extendability:  It is flexible to develop new template class to utilize new architectural features. Template meta-programming is intimate for C++ programmers. It is easy to extend new execution rules and parallel patterns. Other approaches have to ratify languages and then modify compiler to complete features.

\item Portability: Template mechanism are standardized in ISO \cite{b8, b17}. Our template library conforms to standards and is guaranteed to be portable for all mainstreaming C++ compilers.
\end{itemize}

The remaining parts of this paper are structured as follows. Section 2 summarizes some related works on static transformation and other library-based solutions. Section 3 show techniques to perform transforms by template metaprogramming. Audiences with C++ template programming experiences or functional programming concepts are helpful but not prerequisites. Then Section 4 presents some typical transforms by our template library. Experiments are in Section 5 to evaluate effect of specialization. Final section is conclusion and future works.

\section{Related work}
As mentioned before, it is desirable to extend conventional programming languages to reflects the essence of newer hardware. Researches in the field have two major directions:
\begin{enumerate}
\item providing new library to support programming in concurrency
\item extending language constructs to extend parallel semantics
\end{enumerate}

First, library is a common method to extend language capability without introducing new language constructs or modifying grammar. POSIX thread library is a de facto standard to utilize multi-thread for applications on UNIX-compatible systems. The relationship between pthread and native thread provided by OS is straightforward. Therefore, abstraction of pthread is far away from naturally expressing parallelism and concurrency. Furthermore, the implementation of thread on hardware is unspecific in the standard, so it can not guarantee performance or even correctness on some architectures \cite{b4, b5}.

C++ community intends to develop parallel library while bearing generic programming in mind. TBB(Thread Block Builder) has a plenty of containers and execution rules. Entities including partitioner and scheduler in TBB are created in runtime. In that case, key data structures have to be thread-safe. Although TBB exploits task parallelism or other sophisticated concurrency on general purpose processors, the runtime overhead is relative high in data parallel programs, especially in the scenario that massive ALUs are exposed by hardware. Solution we proposed here is orthogonal to runtime parallel libraries. We only explore parallelism that can be determined in compile time, developers feel free to deploy other ways to speedup the programs in runtime, such as TBB.
 
%% MPI
%Another dominant parallel library is MPI in supercomputing community. It based on message-passing mechanism and SPMD model to execute parallel program. The difficulties of developing MPI programs are as notorious as pthread counterpart for programmers without sufficent training of parallel programming. 
%%

Second choice for language communities is to extend semantics by modifying compiler. They add directive or annotation to help compiler transform source code. OpenMP is designed for shared memory and has shipped in almost every C/Fortran compilers. OMP compilers transform sequential code into multi-threaded programs with OMP runtime. Although OpenMP is simple and portable, the performance is not optimal in most cases. A handful of directives leave little room for further enhancement and scaling up to larger systems. Hybrid OpenMP with MPI is possible, but difficulty surges.

Another approach is to add new language constructs. Sequoia is a source-to-source compiler to support programming memory hierarchy. First of all, It targets execution environment as a tree of machines, which an individual machine owns its storage and computation unit. Second, It terms a computation-intensive function as \textit{task}. New constructs apply on \emph{task}. Sequoia compiler transforms a \textit{task} into a cluster of subprocedures based on machines hierarchy. The target machines are described in XML files. Based on this idea, Sequoia actually can specialize task for target architectures. \cite{b2} reports Sequoia can successfully transform codes for CellBE, SMP, cluster while keeping very competitive performance. However, Sequoia as a language extension is restrictive. The basic data structure is array, which obviously shows the preference of scientific computation. The language constructs do not cover all the common parallel patterns such as pipeline and task queue. Libvina derived the idea of Sequoia to transform source code recursively. However, template meta-programming utilizes existing mechanism in C++ compiler and is capable to express all the semantics in Sequoia programming language. Moreover, Sequoia can not leverage type system to specialize code. \textit{e.g.} Many modern processors usually provide SIMD instructions. Libvina could generate corresponding source based on predefined vector types. Sequoia compiler ignores this important information and simply relies on native compilers.

%With the astonishing pace of core proliferation and architecture refinement, GPU has evolved to a pioneer of supercomputing. OpenCL \cite{b12} programming language is strongly affected by vender-dependent predecessor CUDA. It provides a unified computation platform. The downside of OpenCL is the obvious bias toward Streaming architectures. Because OpenCL has to assume its simplest computation unit for target, recursion in kernel function is forbidden in the specification. It is regarded as a simple and neat way to divide problems. Libvina can cooperate with OpenCL to transform code for GPU. It recursively generates tasks and finally emit OpenCL kernel programs while hiding details to user programming. 

\section{A Template library}
\subsection{Overview}
We implemented a template library, libvina, to perform source specialization. One fundation of our approach is that assume C++ compiler front-end as a code generator. It actually practices source-to-source transforms in the guidance of template meta-programming. Defintely, to ulitize static information, we provides a couple of data structures with template parameters to carry such information. When template classes are instantiated , compiler recursively generates codes until specific conditions are statisfied.

In our design philosophy, programmers only care about developing efficient algorithms. Template library takes responsibility for parallelization and optimizstion of memory while keeping the same interface. Porting to another platforms might need to refine template parameters or apply to new templates to obtain maximal performance, however, it is unnecessary for programmers to modify even know details of algorithms.

\subsection{Prerequisites}
%template general
Originally, C++ template mechanism is invented to supersede C preprocessor. It is type-safe and could facility generic programming. People found the potential of template computation by chance. \cite{b6} later proved template itself is Turing completeness. Beside the job it meant to do, template has successfully applied to many innovative purposes in modern C++ programming practices \cite{b9}. 

%template sepcialization
A powerful feature of C++'s templates is template specialization. This allows alternative implementations to be provided based on certain characteristics of the parameterized type that is being instantiated. Template specialization has two purposes: to allow certain forms of optimization, and to reduce code bloat ~\cite{b18}.

%template metaprogramming 
Template meta-programming is similar to functional programming language except it takes effect in compile time. It only relies on static information to determine control flow and perform computation. MPL Library \cite{b16} provides control statement and STL-like data structures, which greatly eases programming in static realm.

\subsection{Concepts}
\subsubsection{TF class}
%TF class
Computation-intensive functions are commonly referred to \emph{kernel} or \emph{filter}. Mathematically, a function is single-target binary relation. Kernel functions are usually self-contained, \textit{i.e.} external data references are limited and calling graphs are simple. It's possible for a kernel function to decouple into a group of subprocedures. Each subprocedure may be exactly the same as kernel and spread on multicore running in parallel.  Another approach is to divide a kernel into finer stages and run in streaming manner to respect data locality and bandwidth. In libvina, a \emph{transform class (TF class)} is a template class which transforms a function to a cluster of subprocedures in isomorphism. As shown in ~\ref{fig:tfcls}, the transformed function on right side has the same interface while owns a call graph to complete the original computation by a cluster of subprocedures. Execution of the call graph can be programmed by in the library to scrutinise target's architecture.


\begin{figure}
\centering
\includegraphics[width=3.3in]{map-class}
\caption{transform class}
\label{fig:tfcls}
\end{figure}

\subsubsection{Polymorphism in compile-time}
In programming language, a function which can applies any values of differnt types are parameteric polymophism. C++ has already supportted this language feature by template function. Our library need to manipulate template functions and instantiate them on demand, which we call it \emph{late-instantiation} inspired of \emph{late-binding}. However, the entry address of a template function is not available until it is instantiated. Therefore, it is desirable to extend function polymorphism in compile-time. Our approach is to wrap the template function by a template class and pass class as template template class. This is the only way to implement late-instantiation. It incurs an extra function call and will be hopefully eliminated by compiler's optimization.

\begin{verbatim}
template<class Result, class Arg0, class Arg1>
struct vecAddWrapper {
 //...
 static void 
 doit(const Arg0& arg0, const Arg1& arg1, 
     Result& result)
 {
    vecArithImpl<T, DIM_N>::add (arg0, arg1, result);
 }
};
\end{verbatim}

%predicate and sentinel
\subsubsection{Predicate}
Borrowed from lisp concept, \emph{predicate} represents a indicator of some conditions. In libvina, it is a template class with static fields initialized by constant expressions consisting of template parameters and constants. These fields are automatically evaluated when template classes are instantiated. ~\ref{lst:pred} is an example to determine whether the problem size is fitting to last level cache.

\makebox[3.1\width]{\hrulefill}
\begin{verbatim}
template <class T, int SIZE_A
     , int SIZE_B, int SIZE_C>
struct p_lt_cache_ll {
 enum {CACHE_LL_SIZE = 4096*1024};
 const static bool value = 
     ((SIZE_A * SIZE_B 
   + SIZE_A * SIZE_C + SIZE_B * SIZE_C) 
   * sizeof(T) ) <= CACHE_LL_SIZE;
};
\end{verbatim}

%\caption{List - 1 : predicate lt\_cache\_ll}

\subsubsection{Sentinel}
\emph{Sentinels} in libvina are non-type template parameters of \emph{TF class}, with a \emph{predicate} as default initializer. When a template class is instantiating, sentinels are evaluated.  A \emph{predicate} determines whether a specific requirement has been satisfied. Sentinel is responsible for changing generation strategy according to the result. Using \emph{template specialization}, C++ compiler chooses different versions of a class to instantiate basing on the values or types of template arguments. The most important application of \emph{sentinel} is terminate code generation. More general flow control such as branch is feassible in ~\cite{16}.

\subsection{Supporting data structure}
%view
Template meta-programing can only manipulate static information. As a result, ADTs in libvina need to carry such information as template parameters. Only Vector and Matrix are implemented in our library, because they cover a wide spectrum of application in multimedia area. Users require more versatile data structures could resort to mature library such as \cite{b10}. As ~\ref{fig:view} depicted, View is a concept to abstract data set. It is not neccessary to duplicate concrete data in shared memory. View classes are divisible and type-safe.

Shadow region is the other thread space. The only approach to communicate with other thread is through ViewMT. We only provide synchronization for ViewMT to encourage bulk operations. ViewMTs can copy in non-blocking, however inducing from ViewMT to normal View is a blocking operation. By this approach, libvina guarantees synchronization by internal signal. We defined a signal class with semphore sematics. It is copyable to support transmitting data set to multiple receivers. In addition, many contemporary multicore architectures ~\cite{b20} have explicit facilities to perform such kind of operation so we can implement it effectively.

\begin{figure}
\includegraphics[width=3.3in]{view_concept}
\caption{View}
\label{fig:view}
\end{figure}
%%
\section{Program specialization}
\subsection{SPMD}
Multi-threading is dominant approach to utilize duplicated computation units. SPMD model is the most intuitive manner to describe parallelism. Furthermore, high performance of SPMD is fundation of streaming model. There are numerous kernel functions in multimedia applications and scientific computations which can easily exploit data parallelism by dividing task into smaller and independent subtasks. This feature naturally matches libvina's transformation. We implemented \emph{mappar} and \emph{mapreduce} language constructs in \cite{b1} as template classes. aux::subview is a meta-functions to deal with cutting off data set. It could return a real subview or itself according to types of template parameters. ~\ref{lst:mappar} gives the definition of arg1\_isomoph, which determintes whether the \textit{arg1} is isomorphic.

~\ref{lst:mappar} is the definition of \emph{mappar TF} class. Template parameter \emph{Instance} is computation task containing a kernel function wrapper and arguments. The last template parameter \emph{\_\_SENTINEL\_\_} determines control flow when instantiation occurs. ~\ref{lst-mappar2} is a template partial specialization to generate concrete thread to practice computation. It is noteworthy that the last two arguments are \emph{true}, which means that this class is multi-threaded and leaf node version. 

\makebox[3.1\width]{\hrulefill}
\begin{verbatim}
template <class Instance, int  _K,
	  bool _IsMT,  bool __SENTINEL__>
struct mappar {
  typedef mappar<typename Instance::SubTask, 
        _K, _IsMT, 
	Instance::SubTask::_pred> _Tail;

  typedef typename mpl::or_<mpl::bool_<std::tr1::is_arithmetic<typename Instance::Arg1>::value>,
			    mpl::bool_<std::tr1::is_same<typename Instance::Arg1, 
							 typename Instance::SubTask::Arg1>
					 ::value>
			      >::type
  arg1_isomorph;
  //...
  static void doit(const typename Instance::Arg0& arg0, 
		   const typename Instance::Arg1& arg1, 
		     typename Instance::Result& result)
  {
     for (int k=0; k < _K; ++k) {
	auto subArg0   = aux::subview<typename Instance::Arg0, 
	    arg0_dim::value, arg0_isomorph::value>::sub_reader(arg0, k);
	  
	auto subArg1   = aux::subview<typename Instance::Arg1,
	    arg1_dim::value, arg1_isomorph::value>::sub_reader(arg1, k); 
	  
	auto subResult = aux::subview<typename Instance::Result,
	    ret_dim::value, ret_isomorph::value>::sub_writer(result, k);

	_Tail::doit(*subArg0, *subArg1, *subResult);
    }//end for
 }
};
\end{verbatim}
\begin{center}
\label{lst:mappar}
\end{center}

\makebox[3.1\width]{\hrulefill}
\begin{verbatim}
template <class Instance, int  _K>
struct mappar <Instance, _K, true, true> 
{
// ...
 static void 
 Doit(const typename Instance::Arg0& arg0, 
   const typename Instance::Arg1& arg1,
   typename Instance::Result& result,
   mt::barrier_t barrier)
 {
   auto compF = Instance::computationMT();

   mt::thread_t leaf(compF, arg0, arg1, 
     __aux::ref(result, result_arithm()), 
     barrier);
 }
};
\end{verbatim}

\begin{figure}
\centering
\includegraphics[width=3.3in]{test_matrix}
\caption{MM internal call graph}
\label{fig:mm}
\end{figure}

~\ref{fig:mm} is a cluster of subprocedures generated by libvina after applying \emph{mapreduce} to a matrix multiplication function. Template parameter \_K is 2 in this case because we perform this transform for dual core machine. Libvina \emph{mapreduce} divides a matrix into 4 sub-matrices. The figure except dashed lines is actually a call graph. Shadow lines is multi-threaded environment and two subprocedures are executed in parallel. Dashed lines indicate logical synchronization. We implemented it by semphore or higher level barrier based on different thread libraries.

\emph{mapseq} in \cite{b1} can be trivially implemented by passing false to \emph{\_IsMT} parameter. Nested block is possible by recursively defining \emph{TF classes}.

\subsection{Streaming and pipelining}
Streaming computation is a computer paradigm to perform massive parallelled computation. It models data set as a \emph{stream}. Operations are usually orangized in pipeline way to process in turn, while keeping stream in on-chip storage. It can utlize duplicated ALUs array to perform computation in parallel and reduce external bandwidth. 

More general streaming computation does not restrict to keep data stationary. Pipeline processing inherently support heterogeneous architecture or ring network ~\cite{b19,b14}. If specific processors are exposed by platform and communition cost is manageable, developers intend to ultize them for throughput or energy advantages. Our template approach has no problem to link external computation as long developers provides communication layers.

Our template library provides two components to support streaming compuation. First of all, we provides a multithreated \emph{ViewMT} classes depicted in ~\ref{fig:view}. Accessing elements from ViewMT is blocking and that thread is supposed to sleep until concerned event arrives. \textit{e.g.} upstreaming thread completes job and release the ownership, this event will wake up sleeping threads and proceeding with data. On shared memory system, we implemented it by plain pointer and semphore. For external accelerator, we implemented by memory map and event provided by OpenCL ~\cite{b12}. Secondly, we provide a TF class to build a pipeline. The simplifed class is enlisted as follows ~\ref{lst:pipe}. The class chains a serie of stages. It is noteworthy that we dedicatedly undefine the end of recursion because framework has no idea how to deal with the output of pipeline. It is user's responsibility to add final stage to clarify behaviors. 

graph to depict multithreaded structure on x86. 

\begin{verbatim}
template <typename... Stages>
struct pipeline;

template <class P, typename... Tail>
struct pipeline<P, Tail...> {
  typedef typename P::input_type in_t;
  typedef typename P::output_type out_t;
 
 static out_t doit(in_t in)
  {
     pipeline<Tail...>::doit(  P::doit(in)  );
  }
};  
\end{verbatim}
\subsection{Blocking}
\subsection{Cooperation with other libraries}
We implemented our library in ISO standard C++. Theoretically, any standard-compliance C++ compiler should process our classes without trouble. C++0X \cite{b17} added a lot of language features to ease template meta-programming. Compilers without C++0X supports need some workarounds to pass compilation. Consider the trend of C++, development of template libraries such as libvina should became easier and smoother in the future. 

We implemented \emph{mt::thread} based on underlying Linux PThread. A simple C++ thread pool is developed to reduce cost of thread creation. SPMD(Single program multiple data) is very important execution model. In order to obtain similiar SPMD execution model on x86, we designed a lightweight thread library(libSPMD) based on Linux clone(2) and semaphore. In order to obtain platform independence, we utilize GPU by OpenCL API. Many Acceleraters are scheduled to implemented OpenCL, which might be extend our approach to new territories in the future. 
 
\section{Experiment and evaluation}
\subsection{Methodology}
C++0X is partially supported by mainstreaming compilers. Currently, we developed the library for gcc 4.4.0. GPU performance was measured on Mac OSX 10.6. 

A couple of algorithms are evaluated for libvina.  They are typical programs in image processing and scientific computations. In addition, we implemented a language translation scenario to illustreate pipeline processing. 
On x86 platform, We linked Intel Math kernel library to perform BLAS functions. Other procedures are implemented on our own. 

\begin{itemize}
\item[saxpy] Procedure in BLAS level 1. A scalar multiplies to a single precision vector, which contains 32 million elements.
\item[sgemm] Procedure in BLAS level 3. Two 4096X4096 dense matrices multiply.
\item[dot\_prod] Two vectors perform dot production.
\item[conv2d] 2-Dimensional convolution operation on image.
\item[lang\_pipe] Pseudo-Multi-language translation. A word is translated from one language A to language B, and then new function will translate it from language B to language C, etc.
\end{itemize}

Three multicore systems are used to conduct experiments. 
\begin{table}[hb]
\caption{Table 1: Experimental machines}
\begin{center}
\begin{tabular}{|l|r|r|l|r|r|}
\hline
name& ISA         & topology   & frequency  & storage-on-chip & bandwidth\\
\hline 
htn & x86 harpertown& 2-way & 2.00Ghz & 6M shared& \\
    &               &quadcores&       & L2 Cache X2&\\           
\hline
nhm & x86 nehalem & quad cores& 2.93Ghz & 256K L2&  \\
    &             &           &         & 8M shared L3&         \\                   
\hline
9400m & gpu g80  & 2 MultiProcessors& 1.10Ghz & 16k local storage& 3.4Gb/s \\
\hline
\end{tabular} 
\end{center}
\end{table}

\subsection{Results}
Figures are preparing...\\
1. speedup on x86\\
2. speedup on GPU.\\
3. table: peak performance for x86 and gpu\\
4. comparison 3 SPMD threads.\\
%5. cache misses reduction in blocking\\
5. comparison between gpu and cpu. matrix-multiplications?
\section{Conclusions and Future work}
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
\newpage

\IEEEtriggeratref{11}

% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,TCRef.bib}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)

\begin{thebibliography}{99}
\setlength{\itemsep}{1mm}
\bibitem{b1} Fatahalian, K., Knight, T., Houston, M., Erez, M., Horn, D.R., Leem, L., Park, J.Y., Ren, M., Aiken, A., Dally, W.J., Hanrahan, P.: Sequoia: Programming The Memory Hierarchy. SC2006
\bibitem{b2} Knight, T. J., Park, J. Y., Ren, M., Houston, M., Erez, M., Fatahalian, K., Aiken, A., Dally, W. J., and Hanrahan, P. Compilation for Explicitly Managed Memory Hierarchies. PPoPP 2007
\bibitem{b3} Aho, A., Sethi, R., Ullman, J.D., Lam, M.: Compilers: Principles, Techniques, and Tools. Addison-Wesley. 
\bibitem{b4} Boehm, H.J.: Threads Cannot Be Implemented As a Library. PLDI '05
\bibitem{b5} Drepper, U., Molnar, I.: The Native POSIX Thread Library for Linux. 2005
\bibitem{b6} Veldhuizen, T. L.: C++ Template are Turing Complete. 
\bibitem{b7} Saha, B., Zhou, X., Chen, H., Gao, Y., Yan, S., Rajagopalan, M., Fang, J., Zhang, P., Ronen, R., Mendelson, A.: Programming Model for Heterogeneous x86 Platform. PLDI '09.
\bibitem{b8} C++ Standard Committee: ISO/IEC 14882:2003(E) Programming Languages — C++, 2003
\bibitem{b9} Alexandrescu, A.: Modern C++ design: generic programming and design patterns applied, 2001
\bibitem{b10} Abrahams, D., Gurtovoy, A.: C++ Template Meta-programming: Concepts, Tools, and Techniques from Boost and Beyond, 2004
\bibitem{b11} Kapasi, U.J., Dally, W.J., Rixner, S., Owens, J.D., Khailany, B.: The Imagine Stream Processor. Proceeding of the 2002 International Conference on Computer Design.
\bibitem{b12} Munshi, A., Khronos OpenCL Working Group, The OpenCL Specification ver.1.0.43, 2009
\bibitem{b13} Goldberg, B.: Functional Programming Language, ACM Computing Surveys, 1996
\bibitem{b14} Seiler, L., Carmean, D., Sprangle, E., Forsyth, T., Abrash, M., Dubey, P., Junkins, S., Lake, A., Sugerman, J., Cavin, R., Espasa, R., Grochowski, E., Juan, T., Hanrahan, P. 2008. Larrabee: A Many–Core x86 Architecture for Visual Computing. ACM Trans. Graph. 27, 3, Article 18 (August 2008), 15 pages. DOI = 10.1145/1360612.1360617 http://doi.acm.org/10.1145/1360612.1360617. 
\bibitem{b15} El-Ghazawi, T., Cantonnet, F., Yao, Y, Rajamony, R.: Developing an Optimized UPC Compiler for Future Architecture
\bibitem{b16} Gurtovoy, A., Abrahams, D.: The BOOST C++ Meta-programming Library
\bibitem{b17} C++ Standard Committee: ISO/IEC DTR 19768 Doc No. 2857, 2009
\bibitem{b18} Stroustrup, B.: The C++ Programming Language (Spcial Edition) Addison Wesley. Reading Mass. USA. 2000. ISBN 0-201-70073-5
\bibitem{b19} J. A. Kahle, M. N. Day, H. P. Hofstee, C. R. Johns, T. R. Maeurer, and D. Shippy: Introduction to the Cell Multiprocessor, IBM Journal of Research and Development 49, No. 4/5, 589-604, 2005
\bibitem{b20} Official OpenMP Specifications, OpenMP Architecture Review Board, 2002, http://www.openmp.org/specs/.
\end{thebibliography}




% that's all folks
\end{document}


